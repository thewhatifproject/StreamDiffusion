#!/usr/bin/env python3
"""
Multi-ControlNet Webcam Demo for StreamDiffusion

This script demonstrates real-time image generation using webcam input with multiple ControlNet configurations.
It loads a config with multiple ControlNets and applies all preprocessing and conditioning to the webcam feed.
"""

import cv2
import torch
import numpy as np
from PIL import Image
import argparse
from pathlib import Path
import sys
import time

# Add StreamDiffusion to path
sys.path.append(str(Path(__file__).parent.parent / "src"))

from streamdiffusion.controlnet import (
    load_controlnet_config, 
    create_controlnet_pipeline,
    ControlNetConfig
)
from streamdiffusion.image_utils import postprocess_image


def main():
    parser = argparse.ArgumentParser(description="Multi-ControlNet Webcam Demo")
    
    # Get the script directory to make paths relative to it
    script_dir = Path(__file__).parent
    default_config = script_dir.parent / "configs" / "controlnet_examples" / "multi_controlnet_example.yaml"
    
    parser.add_argument("--config", type=str, 
                       default=str(default_config),
                       help="Path to multi-ControlNet configuration file")
    parser.add_argument("--camera", type=int, default=0, 
                       help="Camera device index")
    parser.add_argument("--model", type=str,
                       help="Override base model path from config")
    parser.add_argument("--prompt", type=str,
                       help="Override prompt from config")
    parser.add_argument("--show-preprocessed", action="store_true",
                       help="Show preprocessed control images")
    parser.add_argument("--resolution", type=int, default=512,
                       help="Camera and output resolution")
    
    args = parser.parse_args()
    
    print("ðŸŽ¨ Starting Multi-ControlNet Webcam Demo")
    
    # Load configuration
    config = load_controlnet_config(args.config)
    print(f"âœ“ Loaded configuration from {args.config}")
    
    # Validate multi-ControlNet setup
    if len(config.controlnets) < 2:
        print("âš ï¸  Warning: Config has less than 2 ControlNets. Consider using single ControlNet demo.")
    
    # Override parameters if provided
    if args.model:
        config.model_id = args.model
    if args.prompt:
        config.prompt = args.prompt
    
    # Create ControlNet pipeline
    print("ðŸ”„ Creating Multi-ControlNet pipeline...")
    for i, cn in enumerate(config.controlnets):
        print(f"ðŸ“ ControlNet {i}: {cn.model_id} ({cn.preprocessor})")
    pipeline = create_controlnet_pipeline(config)
    print("âœ“ Pipeline created successfully")
    
    # Setup webcam
    cap = cv2.VideoCapture(args.camera)
    if not cap.isOpened():
        print(f"âŒ Could not open camera {args.camera}")
        return
    
    # Set camera resolution
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, args.resolution)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, args.resolution)
    
    print("âœ“ Camera opened successfully")
    print(f"ðŸ“ Prompt: {config.prompt}")
    print(f"ðŸ“ Resolution: {args.resolution}x{args.resolution}")
    print(f"ðŸŽ›ï¸  ControlNet Scales: {[cn.conditioning_scale for cn in config.controlnets]}")
    
    print("\nðŸŽ® Controls:")
    print("  - Press 'q' to quit")
    print("  - Press 's' to save current output")
    print("  - Press 'c' to toggle control images preview")
    print("  - Press '1-9' to adjust ControlNet scale for that index")
    print("  - Press '+' to increase all ControlNet scales")
    print("  - Press '-' to decrease all ControlNet scales")
    print("  - Press 'p' to change prompt interactively")
    
    frame_count = 0
    show_preprocessed = args.show_preprocessed
    fps_counter = []
    
    # Get preprocessor names for display
    preprocessor_names = [cn.preprocessor.replace("_", " ").title() for cn in config.controlnets]
    
    try:
        while True:
            start_time = time.time()
            
            ret, frame = cap.read()
            if not ret:
                print("âŒ Failed to read from camera")
                break
            
            # Convert BGR to RGB
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frame_pil = Image.fromarray(frame_rgb)
            
            # Update all ControlNets with current frame efficiently (process each preprocessor type only once)
            pipeline.update_control_image_efficient(frame_pil)
            
            # Generate image
            x_output = pipeline(frame_pil)
            output_image = postprocess_image(x_output, output_type="pil")[0]
            
            # Convert back to BGR for display
            output_cv = cv2.cvtColor(np.array(output_image), cv2.COLOR_RGB2BGR)
            
            # Create display layout
            display_frame = cv2.resize(frame, (args.resolution, args.resolution))
            output_display = cv2.resize(output_cv, (args.resolution, args.resolution))
            
            if show_preprocessed and len(pipeline.preprocessors) > 0:
                # Get preprocessed images from cache (avoid reprocessing)
                control_images = []
                for i, preprocessor in enumerate(pipeline.preprocessors):
                    if preprocessor is not None:
                        control_pil = pipeline.get_last_processed_image(i)
                        if control_pil is not None:
                            control_cv = cv2.cvtColor(np.array(control_pil), cv2.COLOR_RGB2BGR)
                            control_images.append(control_cv)
                
                if control_images:
                    # Create grid layout: Input | Controls | Output
                    # Resize controls to fit
                    control_size = args.resolution // len(control_images)
                    controls_resized = [cv2.resize(img, (control_size, control_size)) for img in control_images]
                    
                    # Stack controls vertically
                    if len(controls_resized) == 1:
                        controls_column = cv2.resize(controls_resized[0], (args.resolution//2, args.resolution))
                    else:
                        # Stack multiple controls
                        controls_column = np.vstack(controls_resized)
                        if controls_column.shape[0] != args.resolution:
                            controls_column = cv2.resize(controls_column, (args.resolution//2, args.resolution))
                    
                    # Create 3-panel layout
                    input_column = cv2.resize(display_frame, (args.resolution//2, args.resolution))
                    output_column = cv2.resize(output_display, (args.resolution//2, args.resolution))
                    
                    left_panel = np.hstack([input_column, controls_column])
                    combined = np.hstack([left_panel, output_column])
                else:
                    # Fallback to simple layout
                    combined = np.hstack([display_frame, output_display])
            else:
                # Simple side-by-side layout
                combined = np.hstack([display_frame, output_display])
            
            # Calculate FPS
            end_time = time.time()
            frame_time = end_time - start_time
            fps_counter.append(frame_time)
            if len(fps_counter) > 30:  # Keep last 30 frames
                fps_counter.pop(0)
            avg_fps = len(fps_counter) / sum(fps_counter) if fps_counter else 0
            
            # Add info overlay
            current_scales = [f"{scale:.1f}" for scale in pipeline.controlnet_scales]
            info_text = f"Frame: {frame_count} | FPS: {avg_fps:.1f}"
            scales_text = f"Scales: [{', '.join(current_scales)}]"
            
            cv2.putText(combined, info_text, (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            cv2.putText(combined, scales_text, (10, 60), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
            
            # Add preprocessor info
            preprocessors_text = f"Preprocessors: {', '.join(preprocessor_names)}"
            cv2.putText(combined, preprocessors_text, (10, 90), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
            
            cv2.imshow(f'Multi-ControlNet StreamDiffusion', combined)
            frame_count += 1
            
            # Handle key presses
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('s'):
                # Save current output
                try:
                    timestamp = int(time.time())
                    output_path = f"multi_controlnet_output_{timestamp}.png"
                    output_image.save(output_path)
                    print(f"ðŸ’¾ Saved output to {output_path}")
                        
                except Exception as save_error:
                    print(f"âŒ Failed to save: {save_error}")
            elif key == ord('c'):
                # Toggle control images preview
                show_preprocessed = not show_preprocessed
                print(f"ðŸ–¼ï¸  Control images preview: {'ON' if show_preprocessed else 'OFF'}")
            elif key == ord('+'):
                # Increase all scales
                for i in range(len(pipeline.controlnet_scales)):
                    new_scale = min(2.0, pipeline.controlnet_scales[i] + 0.1)
                    pipeline.update_controlnet_scale(i, new_scale)
                scales_str = [f"{s:.1f}" for s in pipeline.controlnet_scales]
                print(f"ðŸ“ˆ All scales: [{', '.join(scales_str)}]")
            elif key == ord('-'):
                # Decrease all scales
                for i in range(len(pipeline.controlnet_scales)):
                    new_scale = max(0.0, pipeline.controlnet_scales[i] - 0.1)
                    pipeline.update_controlnet_scale(i, new_scale)
                scales_str = [f"{s:.1f}" for s in pipeline.controlnet_scales]
                print(f"ðŸ“‰ All scales: [{', '.join(scales_str)}]")
            elif key >= ord('1') and key <= ord('9'):
                # Adjust individual ControlNet scale
                index = key - ord('1')
                if index < len(pipeline.controlnet_scales):
                    print(f"\nðŸŽ›ï¸  Adjusting ControlNet {index} ({preprocessor_names[index]}):")
                    print(f"Current scale: {pipeline.controlnet_scales[index]:.2f}")
                    try:
                        new_scale_input = input("Enter new scale (0.0-2.0): ").strip()
                        if new_scale_input:
                            new_scale = float(new_scale_input)
                            new_scale = max(0.0, min(2.0, new_scale))
                            pipeline.update_controlnet_scale(index, new_scale)
                            print(f"âœ“ Updated ControlNet {index} scale to {new_scale:.2f}")
                    except:
                        print("âŒ Invalid input")
            elif key == ord('p'):
                # Interactive prompt change
                print(f"\nðŸŽ¨ Enter new prompt (or press Enter to keep current):")
                try:
                    new_prompt = input(f"Current: {config.prompt}\nNew: ").strip()
                    if new_prompt:
                        pipeline.stream.update_prompt(new_prompt)
                        config.prompt = new_prompt
                        print(f"âœ“ Updated prompt: {new_prompt}")
                except:
                    print("âŒ Failed to update prompt")

    except KeyboardInterrupt:
        print("\nðŸ›‘ Interrupted by user")
    
    finally:
        cap.release()
        cv2.destroyAllWindows()
        print("ðŸ Multi-ControlNet demo finished")
        if fps_counter:
            avg_fps = len(fps_counter) / sum(fps_counter)
            print(f"ðŸ“Š Average FPS: {avg_fps:.2f}")


if __name__ == "__main__":
    main() 